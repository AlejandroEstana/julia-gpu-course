![Course title page](course_titlepage.png)

#### Course Description

The programming language Julia is being more and more adopted in High Performance Computing (HPC) due to its unique way to combine performance with simplicity and interactivity, enabling unprecedented productivity in HPC development. This course will discuss both basic and advanced topics relevant for single and Multi-GPU computing with Julia. It will focus on the CUDA.jl package, which enables writing native Julia code for GPUs. Topics covered include the following:

-    GPU array programming;
-    GPU kernel programming;
-    kernel launch parameters;
-    usage of on-chip memory;
-    Multi-GPU computing;
-    code reflection and introspection; and
-    diverse advanced optimization techniques.

This course combines lectures and hands-on sessions.

#### Target audience

This course addresses scientists interested in doing HPC using Julia. Previous Julia or GPU computing knowledge is not needed, but a good general understanding of programming is advantageous.

#### Instructors

- Dr. Tim Besard (Lead developer of CUDA.jl, Julia Computing Inc.)
- Dr. Samuel Omlin (Computational Scientist | Responsible for Julia computing, CSCS)

#### Course material

This git repository contains the material of day 1 and 2 (speaker: Dr. Samuel Omlin, CSCS). The material of day 3 and 4 is found in [this git repository](https://github.com/maleadt/cscs_gpu_course/) (speaker: Dr. Tim Besard, Julia Computing Inc.).

#### Course recording
The edited course recording is found [here](https://youtu.be/LmM2QmYw_NM).

Day 1

[00:00: Introduction to the course](https://youtu.be/LmM2QmYw_NM)

[05:02: General introduction to supercomputing](https://youtu.be/LmM2QmYw_NM?t=302)

[14:06: High-speed introduction to GPU computing](https://youtu.be/LmM2QmYw_NM?t=846)

[32:57: Walk through introduction notebook on memory copy and performance evaluation](https://youtu.be/LmM2QmYw_NM?t=1977)


Day 2

[1:24:53: Introduction to day 2](https://youtu.be/LmM2QmYw_NM?t=5093)

[1:39:12: Walk through solutions of exercise 1 and 2](data "transfer" optimisations) (https://youtu.be/LmM2QmYw_NM?t=5952)

[2:34:12: Walk through solutions of exercise 3 and 4](data "transfer" optimisations and distributed parallelization) (https://youtu.be/LmM2QmYw_NM?t=9252)


Day 3

[03:31:57: Introduction to day 3](https://youtu.be/LmM2QmYw_NM?t=12717)

[03:32:59: Presentation of notebook 1: cuda libraries](https://youtu.be/LmM2QmYw_NM?t=12779)

[04:24:31: Presentation of notebook 2: programming models](https://youtu.be/LmM2QmYw_NM?t=15871)

[05:30:46: Presentation of notebook 3: memory management](https://youtu.be/LmM2QmYw_NM?t=19846)

[06:03:48: Presentation of notebook 4: concurrent computing](https://youtu.be/LmM2QmYw_NM?t=21828)


Day 4

[06:27:15: Introduction to day 4](https://youtu.be/LmM2QmYw_NM?t=23235)

[06:28:13: Presentation of notebook 5: application analysis and optimisation](https://youtu.be/LmM2QmYw_NM?t=23293)

[07:35:08: Presentation of notebook 6: kernel analysis and optimisation](https://youtu.be/LmM2QmYw_NM?t=27308)
